{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28649551-9a04-4305-bceb-16b6a51c1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935625c2-1ddd-442b-b74c-8d27822543a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f302f8d9-066f-4362-8ebf-7fa48de20ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataframe\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81c2b8d-c835-4d7f-a1bd-e7b77383fd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics:\n",
      "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
      "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
      "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
      "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
      "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
      "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
      "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
      "max    150.000000       7.900000      4.400000       6.900000      2.500000\n"
     ]
    }
   ],
   "source": [
    "# Get descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c44388-0c9b-4e39-9f30-28e387f56d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values before cleaning:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dd4191-73a8-4034-93d5-aa4279f67444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                 int64\n",
      "SepalLengthCm    float64\n",
      "SepalWidthCm     float64\n",
      "PetalLengthCm    float64\n",
      "PetalWidthCm     float64\n",
      "Species           object\n",
      "dtype: object\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "Species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class distribution (for classification)\n",
    "print(df[\"Species\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde7eaff-d371-4303-a41d-61e78ad862e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "# Correct (already 1D)\n",
    "y = iris.target\n",
    "\n",
    "# If you accidentally made it 2D:\n",
    "y_wrong = iris.target.reshape(-1, 1)  # Shape (150, 1)\n",
    "y_fixed = y_wrong.ravel()  # Now shape (150,)\n",
    "\n",
    "# Now this will work:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_fixed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a7245f-8e97-4414-9ebc-64d5a6a5e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset overview:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   species  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "\n",
      "Class distribution:\n",
      "species\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Checking for missing values:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "dtype: int64\n",
      "\n",
      "Data split results:\n",
      "Training set size: 105 samples\n",
      "Test set size: 45 samples\n",
      "\n",
      "Class distribution in training set:\n",
      "1    35\n",
      "0    35\n",
      "2    35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in test set:\n",
      "2    15\n",
      "1    15\n",
      "0    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training Decision Tree Classifier...\n",
      "\n",
      "Feature importances:\n",
      "sepal length (cm): 0.0000\n",
      "sepal width (cm): 0.0286\n",
      "petal length (cm): 0.5412\n",
      "petal width (cm): 0.4303\n",
      "\n",
      "Model Evaluation:\n",
      "Accuracy: 0.9333\n",
      "Precision: 0.9444\n",
      "Recall: 0.9333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      0.80      0.89        15\n",
      "   virginica       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Load the Iris dataset\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the Iris dataset from scikit-learn.\n",
    "    Returns features (X) and target labels (y).\n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "    X = iris.data  # Features (sepal/petal measurements)\n",
    "    y = iris.target  # Labels (0=setosa, 1=versicolor, 2=virginica)\n",
    "    \n",
    "    # Convert to DataFrame for better visualization (optional)\n",
    "    iris_df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "    iris_df['species'] = y\n",
    "    \n",
    "    print(\"\\nDataset overview:\")\n",
    "    print(iris_df.head())\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(iris_df['species'].value_counts())\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "def preprocess_data(X, y):\n",
    "    \"\"\"\n",
    "    Handle data preprocessing including:\n",
    "    - Checking for missing values\n",
    "    - Encoding labels (if needed)\n",
    "    \"\"\"\n",
    "    # Check for missing values\n",
    "    print(\"\\nChecking for missing values:\")\n",
    "    print(pd.DataFrame(X).isnull().sum())\n",
    "    \n",
    "    # Note: The Iris dataset is typically clean, but here's how we'd handle missing values\n",
    "    # if pd.DataFrame(X).isnull().sum().any():\n",
    "    #     from sklearn.impute import SimpleImputer\n",
    "    #     imputer = SimpleImputer(strategy='mean')\n",
    "    #     X = imputer.fit_transform(X)\n",
    "    \n",
    "    # Label encoding (already done in this dataset, but here's the general approach)\n",
    "    if isinstance(y[0], str):  # If labels are strings\n",
    "        print(\"\\nEncoding string labels to numerical values...\")\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Step 3: Split data into training and test sets\n",
    "def split_data(X, y, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Split dataset into training and test sets.\n",
    "    Uses stratification to maintain class distribution.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"\\nData split results:\")\n",
    "    print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "    print(\"\\nClass distribution in training set:\")\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print(\"\\nClass distribution in test set:\")\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Step 4: Train Decision Tree Classifier\n",
    "def train_model(X_train, y_train, random_state=42):\n",
    "    \"\"\"\n",
    "    Train a decision tree classifier on the training data.\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining Decision Tree Classifier...\")\n",
    "    model = DecisionTreeClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Display feature importances\n",
    "    print(\"\\nFeature importances:\")\n",
    "    for name, importance in zip(load_iris().feature_names, model.feature_importances_):\n",
    "        print(f\"{name}: {importance:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on test data using:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - Classification report\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=load_iris().target_names))\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    # Step 1: Load data\n",
    "    X, y = load_data()\n",
    "    \n",
    "    # Step 2: Preprocess data\n",
    "    X, y = preprocess_data(X, y)\n",
    "    \n",
    "    # Step 3: Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    # Step 4: Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Step 5: Evaluate model\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59edf8-64ee-4829-bdef-8b6f2e5563a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
